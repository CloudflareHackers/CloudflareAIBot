import { AiTextGeneration } from "./tasks/text-generation";
import { AiTextClassification } from "./tasks/text-classification";
import { AiTextEmbeddings } from "./tasks/text-embeddings";
import { AiTranslation } from "./tasks/translation";
import { AiSpeechRecognition } from "./tasks/speech-recognition";
import { AiImageClassification } from "./tasks/image-classification";
import { AiImageToText } from "./tasks/image-to-text";
import { AiObjectDetection } from "./tasks/object-detection";
import { AiTextToImage } from "./tasks/text-to-image";
import { AiSentenceSimilarity } from "./tasks/sentence-similarity";
import { AiSummarization } from "./tasks/summarization";
import { Tensor, TensorType } from "./tensor";
export declare const modelMappings: {
    readonly "text-classification": {
        readonly models: readonly ["@cf/huggingface/distilbert-sst-2-int8", "@cf/jpmorganchase/roberta-spam"];
        readonly class: typeof AiTextClassification;
        readonly id: "19606750-23ed-4371-aab2-c20349b53a60";
    };
    readonly "text-to-image": {
        readonly models: readonly ["@cf/stabilityai/stable-diffusion-xl-base-1.0", "@cf/runwayml/stable-diffusion-v1-5-inpainting", "@cf/runwayml/stable-diffusion-v1-5-img2img", "@cf/lykon/dreamshaper-8-lcm", "@cf/bytedance/stable-diffusion-xl-lightning"];
        readonly class: typeof AiTextToImage;
        readonly id: "3d6e1f35-341b-4915-a6c8-9a7142a9033a";
    };
    readonly "sentence-similarity": {
        readonly models: readonly ["@hf/sentence-transformers/all-minilm-l6-v2"];
        readonly class: typeof AiSentenceSimilarity;
        readonly id: "69bf4e84-441e-401a-bdfc-256fd54d0fff";
    };
    readonly "text-embeddings": {
        readonly models: readonly ["@cf/baai/bge-small-en-v1.5", "@cf/baai/bge-base-en-v1.5", "@cf/baai/bge-large-en-v1.5", "@hf/baai/bge-base-en-v1.5"];
        readonly class: typeof AiTextEmbeddings;
        readonly id: "0137cdcf-162a-4108-94f2-1ca59e8c65ee";
    };
    readonly "speech-recognition": {
        readonly models: readonly ["@cf/openai/whisper"];
        readonly class: typeof AiSpeechRecognition;
        readonly id: "dfce1c48-2a81-462e-a7fd-de97ce985207";
    };
    readonly "image-classification": {
        readonly models: readonly ["@cf/microsoft/resnet-50"];
        readonly class: typeof AiImageClassification;
        readonly id: "00cd182b-bf30-4fc4-8481-84a3ab349657";
    };
    readonly "object-detection": {
        readonly models: readonly ["@cf/facebook/detr-resnet-50"];
        readonly class: typeof AiObjectDetection;
        readonly id: "9c178979-90d9-49d8-9e2c-0f1cf01815d4";
    };
    readonly "text-generation": {
        readonly models: readonly ["@cf/meta/llama-2-7b-chat-int8", "@cf/mistral/mistral-7b-instruct-v0.1", "@cf/meta/llama-2-7b-chat-fp16", "@hf/thebloke/llama-2-13b-chat-awq", "@hf/thebloke/zephyr-7b-beta-awq", "@hf/thebloke/mistral-7b-instruct-v0.1-awq", "@hf/thebloke/codellama-7b-instruct-awq", "@hf/thebloke/openchat_3.5-awq", "@hf/thebloke/openhermes-2.5-mistral-7b-awq", "@hf/thebloke/starling-lm-7b-alpha-awq", "@hf/thebloke/orca-2-13b-awq", "@hf/thebloke/neural-chat-7b-v3-1-awq", "@hf/thebloke/llamaguard-7b-awq", "@hf/thebloke/deepseek-coder-6.7b-base-awq", "@hf/thebloke/deepseek-coder-6.7b-instruct-awq", "@cf/deepseek-ai/deepseek-math-7b-base", "@cf/deepseek-ai/deepseek-math-7b-instruct", "@cf/defog/sqlcoder-7b-2", "@cf/openchat/openchat-3.5-0106", "@cf/tiiuae/falcon-7b-instruct", "@cf/thebloke/discolm-german-7b-v1-awq", "@cf/qwen/qwen1.5-0.5b-chat", "@cf/qwen/qwen1.5-1.8b-chat", "@cf/qwen/qwen1.5-7b-chat-awq", "@cf/qwen/qwen1.5-14b-chat-awq", "@cf/tinyllama/tinyllama-1.1b-chat-v1.0", "@cf/microsoft/phi-2", "@cf/thebloke/yarn-mistral-7b-64k-awq"];
        readonly class: typeof AiTextGeneration;
        readonly id: "c329a1f9-323d-4e91-b2aa-582dd4188d34";
    };
    readonly translation: {
        readonly models: readonly ["@cf/meta/m2m100-1.2b"];
        readonly class: typeof AiTranslation;
        readonly id: "f57d07cb-9087-487a-bbbf-bc3e17fecc4b";
    };
    readonly summarization: {
        readonly models: readonly ["@cf/facebook/bart-large-cnn"];
        readonly class: typeof AiSummarization;
        readonly id: "6f4e65d8-da0f-40d2-9aa4-db582a5a04fd";
    };
    readonly "image-to-text": {
        readonly models: readonly ["@cf/unum/uform-gen2-qwen-500m"];
        readonly class: typeof AiImageToText;
        readonly id: "882a91d1-c331-4eec-bdad-834c919942a8";
    };
};
export declare const modelSettings: {
    "@hf/thebloke/deepseek-coder-6.7b-instruct-awq": {
        type: string;
        inputsDefaultsStream: {
            max_tokens: number;
        };
        inputsDefaults: {
            max_tokens: number;
        };
        preProcessingArgs: {
            promptTemplate: string;
            defaultContext: string;
        };
        postProcessingFunc: (r: any, inputs: any) => any;
        postProcessingFuncStream: (r: any, inputs: any, len: number) => any;
    };
    "@hf/thebloke/deepseek-coder-6.7b-base-awq": {
        type: string;
        inputsDefaultsStream: {
            max_tokens: number;
        };
        inputsDefaults: {
            max_tokens: number;
        };
        preProcessingArgs: {
            promptTemplate: string;
            defaultContext: string;
        };
        postProcessingFunc: (r: any, inputs: any) => any;
        postProcessingFuncStream: (r: any, inputs: any, len: number) => any;
    };
    "@hf/thebloke/llamaguard-7b-awq": {
        type: string;
        inputsDefaultsStream: {
            max_tokens: number;
        };
        inputsDefaults: {
            max_tokens: number;
        };
        preProcessingArgs: {
            promptTemplate: string;
            defaultContext: string;
        };
        postProcessingFunc: (r: any, inputs: any) => any;
        postProcessingFuncStream: (r: any, inputs: any, len: number) => any;
    };
    "@hf/thebloke/openchat_3.5-awq": {
        experimental: boolean;
        type: string;
        inputsDefaultsStream: {
            max_tokens: number;
        };
        inputsDefaults: {
            max_tokens: number;
        };
        preProcessingArgs: {
            promptTemplate: string;
            defaultContext: string;
        };
        postProcessingFunc: (r: any, inputs: any) => any;
        postProcessingFuncStream: (r: any, inputs: any, len: number) => any;
    };
    "@hf/thebloke/openhermes-2.5-mistral-7b-awq": {
        type: string;
        inputsDefaultsStream: {
            max_tokens: number;
        };
        inputsDefaults: {
            max_tokens: number;
        };
        preProcessingArgs: {
            promptTemplate: string;
            defaultContext: string;
        };
        postProcessingFunc: (r: any, inputs: any) => any;
        postProcessingFuncStream: (r: any, inputs: any, len: number) => any;
    };
    "@hf/thebloke/starling-lm-7b-alpha-awq": {
        experimental: boolean;
        type: string;
        inputsDefaultsStream: {
            max_tokens: number;
        };
        inputsDefaults: {
            max_tokens: number;
        };
        preProcessingArgs: {
            promptTemplate: string;
            defaultContext: string;
        };
        postProcessingFunc: (r: any, inputs: any) => any;
        postProcessingFuncStream: (r: any, inputs: any, len: number) => any;
    };
    "@hf/thebloke/orca-2-13b-awq": {
        experimental: boolean;
        type: string;
        inputsDefaultsStream: {
            max_tokens: number;
        };
        inputsDefaults: {
            max_tokens: number;
        };
        preProcessingArgs: {
            promptTemplate: string;
            defaultContext: string;
        };
        postProcessingFunc: (r: any, inputs: any) => any;
        postProcessingFuncStream: (r: any, inputs: any, len: number) => any;
    };
    "@hf/thebloke/neural-chat-7b-v3-1-awq": {
        type: string;
        inputsDefaultsStream: {
            max_tokens: number;
        };
        inputsDefaults: {
            max_tokens: number;
        };
        preProcessingArgs: {
            promptTemplate: string;
            defaultContext: string;
        };
        postProcessingFunc: (r: any, inputs: any) => any;
        postProcessingFuncStream: (r: any, inputs: any, len: number) => any;
    };
    "@hf/thebloke/llama-2-13b-chat-awq": {
        type: string;
        inputsDefaultsStream: {
            max_tokens: number;
        };
        inputsDefaults: {
            max_tokens: number;
        };
        preProcessingArgs: {
            promptTemplate: string;
            defaultContext: string;
        };
        postProcessingFunc: (r: any, inputs: any) => any;
        postProcessingFuncStream: (r: any, inputs: any, len: number) => any;
    };
    "@hf/thebloke/zephyr-7b-beta-awq": {
        type: string;
        inputsDefaultsStream: {
            max_tokens: number;
        };
        inputsDefaults: {
            max_tokens: number;
        };
        preProcessingArgs: {
            promptTemplate: string;
            defaultContext: string;
        };
        postProcessingFunc: (r: any, inputs: any) => any;
        postProcessingFuncStream: (r: any, inputs: any, len: number) => any;
    };
    "@hf/thebloke/mistral-7b-instruct-v0.1-awq": {
        type: string;
        inputsDefaultsStream: {
            max_tokens: number;
        };
        inputsDefaults: {
            max_tokens: number;
        };
        preProcessingArgs: {
            promptTemplate: string;
            defaultContext: string;
        };
        postProcessingFunc: (r: any, inputs: any) => any;
        postProcessingFuncStream: (r: any, inputs: any, len: number) => any;
    };
    "@hf/thebloke/codellama-7b-instruct-awq": {
        type: string;
        inputsDefaultsStream: {
            max_tokens: number;
        };
        inputsDefaults: {
            max_tokens: number;
        };
        preProcessingArgs: {
            promptTemplate: string;
            defaultContext: string;
        };
        postProcessingFunc: (r: any, inputs: any) => any;
        postProcessingFuncStream: (r: any, inputs: any, len: number) => any;
    };
    "@cf/thebloke/yarn-mistral-7b-64k-awq": {
        experimental: boolean;
        type: string;
        inputsDefaultsStream: {
            max_tokens: number;
        };
        inputsDefaults: {
            max_tokens: number;
        };
        preProcessingArgs: {
            promptTemplate: string;
            defaultContext: string;
        };
        generateTensorsFunc: (preProcessedInputs: any) => Tensor<TensorType.String>[];
        postProcessingFunc: (r: any, inputs: any) => any;
        postProcessingFuncStream: (r: any, inputs: any, inclen: any) => any;
    };
    "@cf/microsoft/phi-2": {
        type: string;
        inputsDefaultsStream: {
            max_tokens: number;
        };
        inputsDefaults: {
            max_tokens: number;
        };
        preProcessingArgs: {
            promptTemplate: string;
            defaultContext: string;
        };
        generateTensorsFunc: (preProcessedInputs: any) => Tensor<TensorType.String>[];
        postProcessingFunc: (r: any, inputs: any) => any;
        postProcessingFuncStream: (r: any, inputs: any, inclen: any) => any;
    };
    "@cf/defog/sqlcoder-7b-2": {
        preProcessingArgs: {
            promptTemplate: string;
            defaultContext: string;
        };
        type: string;
        inputsDefaultsStream: {
            max_tokens: number;
        };
        inputsDefaults: {
            max_tokens: number;
        };
        generateTensorsFunc: (preProcessedInputs: any) => Tensor<TensorType.String>[];
        postProcessingFunc: (r: any, inputs: any) => any;
        postProcessingFuncStream: (r: any, inputs: any, inclen: any) => any;
    };
    "@cf/deepseek-ai/deepseek-math-7b-base": {
        type: string;
        inputsDefaultsStream: {
            max_tokens: number;
        };
        inputsDefaults: {
            max_tokens: number;
        };
        preProcessingArgs: {
            promptTemplate: string;
            defaultContext: string;
        };
        generateTensorsFunc: (preProcessedInputs: any) => Tensor<TensorType.String>[];
        postProcessingFunc: (r: any, inputs: any) => any;
        postProcessingFuncStream: (r: any, inputs: any, inclen: any) => any;
    };
    "@cf/deepseek-ai/deepseek-math-7b-instruct": {
        type: string;
        inputsDefaultsStream: {
            max_tokens: number;
        };
        inputsDefaults: {
            max_tokens: number;
        };
        preProcessingArgs: {
            promptTemplate: string;
            defaultContext: string;
        };
        generateTensorsFunc: (preProcessedInputs: any) => Tensor<TensorType.String>[];
        postProcessingFunc: (r: any, inputs: any) => any;
        postProcessingFuncStream: (r: any, inputs: any, inclen: any) => any;
    };
    "@cf/tiiuae/falcon-7b-instruct": {
        preProcessingArgs: {
            promptTemplate: string;
            defaultContext: string;
        };
        type: string;
        inputsDefaultsStream: {
            max_tokens: number;
        };
        inputsDefaults: {
            max_tokens: number;
        };
        generateTensorsFunc: (preProcessedInputs: any) => Tensor<TensorType.String>[];
        postProcessingFunc: (r: any, inputs: any) => any;
        postProcessingFuncStream: (r: any, inputs: any, inclen: any) => any;
    };
    "@cf/thebloke/discolm-german-7b-v1-awq": {
        preProcessingArgs: {
            promptTemplate: string;
            defaultContext: string;
        };
        type: string;
        inputsDefaultsStream: {
            max_tokens: number;
        };
        inputsDefaults: {
            max_tokens: number;
        };
        generateTensorsFunc: (preProcessedInputs: any) => Tensor<TensorType.String>[];
        postProcessingFunc: (r: any, inputs: any) => any;
        postProcessingFuncStream: (r: any, inputs: any, inclen: any) => any;
    };
    "@cf/qwen/qwen1.5-14b-chat-awq": {
        preProcessingArgs: {
            promptTemplate: string;
            defaultContext: string;
        };
        type: string;
        inputsDefaultsStream: {
            max_tokens: number;
        };
        inputsDefaults: {
            max_tokens: number;
        };
        generateTensorsFunc: (preProcessedInputs: any) => Tensor<TensorType.String>[];
        postProcessingFunc: (r: any, inputs: any) => any;
        postProcessingFuncStream: (r: any, inputs: any, inclen: any) => any;
    };
    "@cf/qwen/qwen1.5-0.5b-chat": {
        preProcessingArgs: {
            promptTemplate: string;
            defaultContext: string;
        };
        type: string;
        inputsDefaultsStream: {
            max_tokens: number;
        };
        inputsDefaults: {
            max_tokens: number;
        };
        generateTensorsFunc: (preProcessedInputs: any) => Tensor<TensorType.String>[];
        postProcessingFunc: (r: any, inputs: any) => any;
        postProcessingFuncStream: (r: any, inputs: any, inclen: any) => any;
    };
    "@cf/qwen/qwen1.5-1.8b-chat": {
        preProcessingArgs: {
            promptTemplate: string;
            defaultContext: string;
        };
        type: string;
        inputsDefaultsStream: {
            max_tokens: number;
        };
        inputsDefaults: {
            max_tokens: number;
        };
        generateTensorsFunc: (preProcessedInputs: any) => Tensor<TensorType.String>[];
        postProcessingFunc: (r: any, inputs: any) => any;
        postProcessingFuncStream: (r: any, inputs: any, inclen: any) => any;
    };
    "@cf/qwen/qwen1.5-7b-chat-awq": {
        preProcessingArgs: {
            promptTemplate: string;
            defaultContext: string;
        };
        type: string;
        inputsDefaultsStream: {
            max_tokens: number;
        };
        inputsDefaults: {
            max_tokens: number;
        };
        generateTensorsFunc: (preProcessedInputs: any) => Tensor<TensorType.String>[];
        postProcessingFunc: (r: any, inputs: any) => any;
        postProcessingFuncStream: (r: any, inputs: any, inclen: any) => any;
    };
    "@cf/tinyllama/tinyllama-1.1b-chat-v1.0": {
        preProcessingArgs: {
            promptTemplate: string;
            defaultContext: string;
        };
        type: string;
        inputsDefaultsStream: {
            max_tokens: number;
        };
        inputsDefaults: {
            max_tokens: number;
        };
        generateTensorsFunc: (preProcessedInputs: any) => Tensor<TensorType.String>[];
        postProcessingFunc: (r: any, inputs: any) => any;
        postProcessingFuncStream: (r: any, inputs: any, inclen: any) => any;
    };
    "@cf/openchat/openchat-3.5-0106": {
        preProcessingArgs: {
            promptTemplate: string;
            defaultContext: string;
        };
        type: string;
        inputsDefaultsStream: {
            max_tokens: number;
        };
        inputsDefaults: {
            max_tokens: number;
        };
        generateTensorsFunc: (preProcessedInputs: any) => Tensor<TensorType.String>[];
        postProcessingFunc: (r: any, inputs: any) => any;
        postProcessingFuncStream: (r: any, inputs: any, inclen: any) => any;
    };
    "@cf/unum/uform-gen2-qwen-500m": {
        postProcessingFunc: (response: any, inputs: any) => any;
    };
    "@cf/jpmorganchase/roberta-spam": {
        experimental: boolean;
    };
    "@hf/sentence-transformers/all-minilm-l6-v2": {
        experimental: boolean;
    };
    "@hf/baai/bge-base-en-v1.5": {
        postProcessingFunc: (r: any, inputs: any) => {
            shape: any;
            data: any;
        };
    };
    "@cf/meta/llama-2-7b-chat-fp16": {
        inputsDefaultsStream: {
            max_tokens: number;
        };
        inputsDefaults: {
            max_tokens: number;
        };
        preProcessingArgs: {
            promptTemplate: string;
            defaultContext: string;
        };
    };
    "@cf/meta/llama-2-7b-chat-int8": {
        inputsDefaultsStream: {
            max_tokens: number;
        };
        inputsDefaults: {
            max_tokens: number;
        };
        preProcessingArgs: {
            promptTemplate: string;
            defaultContext: string;
        };
    };
    "@cf/openai/whisper": {
        postProcessingFunc: (response: any, inputs: any) => {
            text: any;
            word_count: number;
            words: any;
        } | {
            text: any;
            word_count?: undefined;
            words?: undefined;
        };
    };
    "@cf/mistral/mistral-7b-instruct-v0.1": {
        inputsDefaultsStream: {
            max_tokens: number;
        };
        inputsDefaults: {
            max_tokens: number;
        };
        preProcessingArgs: {
            promptTemplate: string;
            defaultContext: string;
        };
    };
};
export declare const addModel: (task: string, model: string, settings: any) => void;
//# sourceMappingURL=catalog.d.ts.map